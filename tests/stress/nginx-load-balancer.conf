# Nginx load balancer configuration for chat services
upstream backend_servers {
    least_conn;
    server localhost:3000 weight=1 max_fails=3 fail_timeout=30s;
    server localhost:3001 weight=1 max_fails=3 fail_timeout=30s;
    server localhost:3002 weight=1 max_fails=3 fail_timeout=30s;
}

upstream ollama_servers {
    least_conn;
    server localhost:11434 weight=1 max_fails=3 fail_timeout=30s;
    server localhost:11435 weight=1 max_fails=3 fail_timeout=30s;
}

server {
    listen 80;
    server_name chat.yourdomain.com;
    
    # Backend API
    location /api/ {
        proxy_pass http://backend_servers;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_connect_timeout 60s;
        proxy_send_timeout 120s;
        proxy_read_timeout 120s;
    }
    
    # Ollama API
    location /ollama/ {
        proxy_pass http://ollama_servers/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_connect_timeout 60s;
        proxy_send_timeout 180s;
        proxy_read_timeout 180s;
    }
}
